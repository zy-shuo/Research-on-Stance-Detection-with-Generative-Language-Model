# åŸºäºç”Ÿæˆå¼è¯­è¨€æ¨¡å‹çš„ç«‹åœºæ£€æµ‹ç ”ç©¶

æœ¬é¡¹ç›®å®ç°äº†å¤šç§åŸºäºç”Ÿæˆå¼è¯­è¨€æ¨¡å‹çš„ç«‹åœºæ£€æµ‹æ–¹æ³•ï¼ŒåŒ…æ‹¬å¤§è¯­è¨€æ¨¡å‹ï¼ˆGPTã€ChatGLMï¼‰çš„é›¶æ ·æœ¬/å°‘æ ·æœ¬å­¦ä¹ ï¼Œä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ï¼ˆBERTã€RoBERTaã€T5ï¼‰çš„å¾®è°ƒæ–¹æ³•ã€‚

## ğŸ¯ é¡¹ç›®ç®€ä»‹

ç«‹åœºæ£€æµ‹ï¼ˆStance Detectionï¼‰æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¸€é¡¹é‡è¦ä»»åŠ¡ï¼Œæ—¨åœ¨åˆ¤æ–­æ–‡æœ¬å¯¹ç‰¹å®šç›®æ ‡çš„æ€åº¦å€¾å‘ï¼ˆæ”¯æŒã€åå¯¹æˆ–ä¸­ç«‹ï¼‰ã€‚æœ¬é¡¹ç›®é’ˆå¯¹ä¸­æ–‡ç¤¾äº¤åª’ä½“ï¼ˆå¾®åšï¼‰åœºæ™¯ï¼Œå®ç°äº†å¤šç§åŸºäºç”Ÿæˆå¼è¯­è¨€æ¨¡å‹çš„ç«‹åœºæ£€æµ‹æ–¹æ³•ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
Research-on-Stance-Detection-with-Generative-Language-Model/
â”œâ”€â”€ LLMs/                      # å¤§è¯­è¨€æ¨¡å‹æ¨¡å—
â”‚   â”œâ”€â”€ config.py             # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ prompt_templates.py   # Promptæ¨¡æ¿
â”‚   â”œâ”€â”€ gpt_client.py         # GPTå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ glm_client.py         # ChatGLMå®¢æˆ·ç«¯
â”‚   â””â”€â”€ README.md             # æ¨¡å—æ–‡æ¡£
â”‚
â”œâ”€â”€ bert&roberta/             # BERT/RoBERTaå¾®è°ƒæ¨¡å—
â”‚   â”œâ”€â”€ config.py             # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ model.py              # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ data_loader.py        # æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ trainer.py            # è®­ç»ƒæ¨¡å—
â”‚   â”œâ”€â”€ evaluator.py          # è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ main_train.py         # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ main_test.py          # æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ README.md             # æ¨¡å—æ–‡æ¡£
â”‚
â”œâ”€â”€ t5/                       # T5å¾®è°ƒæ¨¡å—
â”‚   â”œâ”€â”€ config.py             # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ data_utils.py         # æ•°æ®å·¥å…·
â”‚   â”œâ”€â”€ data_loader.py        # æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ trainer.py            # è®­ç»ƒæ¨¡å—
â”‚   â”œâ”€â”€ evaluator.py          # è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ main_train.py         # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ main_test.py          # æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ classes_map.json      # ç±»åˆ«æ˜ å°„
â”‚   â””â”€â”€ README.md             # æ¨¡å—æ–‡æ¡£
â”‚
â”œâ”€â”€ data/                     # æ•°æ®é›†
â”‚   â”œâ”€â”€ v1/                   # æ•°æ®é›†v1
â”‚   â”œâ”€â”€ v2/                   # æ•°æ®é›†v2ï¼ˆæ¨èï¼‰
â”‚   â””â”€â”€ README.md             # æ•°æ®é›†è¯´æ˜
â”‚
â”œâ”€â”€ requirements.txt          # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                 # æœ¬æ–‡æ¡£
```

## ğŸ“Š æ•°æ®é›†

### å¾®åšç«‹åœºæ£€æµ‹æ•°æ®é›†

æœ¬é¡¹ç›®ä½¿ç”¨çš„æ˜¯ä¸­æ–‡å¾®åšç«‹åœºæ£€æµ‹æ•°æ®é›†ï¼ŒåŒ…å«5ä¸ªçƒ­ç‚¹äº‹ä»¶ï¼š

1. **å”å±±æ‰“äººäº‹ä»¶** - æ¶æ„æ®´æ‰“ä»–äººè€…çš„å¦»å¥³è¢«ç½‘æš´
2. **èƒ¡é‘«å®‡å¤±è¸ªäº‹ä»¶** - è­¦æ–¹é€šå‘Šèƒ¡é‘«å®‡ä¸ºè‡ªæ€
3. **å¥³å•æ‰€äº‰è®®** - å¥³å­ä¸è®©6å²ç”·ç«¥ä¸Šå¥³å•æ‰€é­ç—›éª‚
4. **æ»¡æ±Ÿçº¢äº‰è®®** - æ»¡æ±Ÿçº¢èµ·è¯‰å¤§V
5. **æ³¼æ°´èŠ‚äº‹ä»¶** - å¥³å­æ³¼æ°´èŠ‚è¢«å›´ç€æ³¼æ°´æ’•é›¨è¡£

### æ•°æ®ç»Ÿè®¡

- **æ€»æ•°æ®é‡**: 2500æ¡
- **è®­ç»ƒé›†**: 2000æ¡ï¼ˆæ¯ä¸ªäº‹ä»¶400æ¡ï¼‰
- **æµ‹è¯•é›†**: 500æ¡ï¼ˆæ¯ä¸ªäº‹ä»¶100æ¡ï¼‰

### æ•°æ®æ ¼å¼

```json
{
    "label": 0,
    "text": "è¯„è®ºæ–‡æœ¬",
    "target": "ç›®æ ‡äº‹ä»¶",
    "ç«‹åœºæ ‡ç­¾": "æ”¯æŒ",
    "ç®€çº¦èƒŒæ™¯": "äº‹ä»¶èƒŒæ™¯ç®€è¿°",
    "å…¨éƒ¨èƒŒæ™¯": "äº‹ä»¶èƒŒæ™¯è¯¦ç»†æè¿°",
    "æ˜ç¡®çš„ç«‹åœºæ ‡ç­¾": "()"
}
```

**æ ‡ç­¾è¯´æ˜**:
- `0`: æ”¯æŒ (favor)
- `1`: åå¯¹ (against)
- `2`: ä¸­ç«‹ (neutral)

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [data/README.md](data/README.md)

## ğŸ”§ ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- CUDA 11.0+ (ä½¿ç”¨GPUæ—¶)
- 8GB+ RAM
- 10GB+ ç£ç›˜ç©ºé—´ï¼ˆç”¨äºå­˜å‚¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**

```bash
git clone https://github.com/yourusername/Research-on-Stance-Detection-with-Generative-Language-Model.git
cd Research-on-Stance-Detection-with-Generative-Language-Model
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰**

```bash
# ä½¿ç”¨conda
conda create -n stance python=3.8
conda activate stance

# æˆ–ä½¿ç”¨venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate  # Windows
```

3. **å®‰è£…ä¾èµ–**

```bash
pip install -r requirements.txt
```

4. **ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹**

- **BERT/RoBERTa**: ä» [Hugging Face](https://huggingface.co/models) ä¸‹è½½ä¸­æ–‡BERTæˆ–RoBERTaæ¨¡å‹
- **T5**: ä¸‹è½½ [mT5](https://huggingface.co/google/mt5-base) æˆ–ä¸­æ–‡T5æ¨¡å‹
- **ChatGLM**: ä¸‹è½½ [ChatGLM2-6B](https://huggingface.co/THUDM/chatglm2-6b)

å°†æ¨¡å‹æ”¾ç½®åœ¨ç›¸åº”çš„ç›®å½•ä¸‹ï¼Œå¹¶åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šè·¯å¾„ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰

#### GPT

```python
from LLMs.gpt_client import GPTClient
from LLMs.config import LLMConfig
import pandas as pd

# é…ç½®
config = LLMConfig(
    api_key="your-api-key",
    data_file="data/v2/test.xlsx",
    output_file="gpt_output.txt"
)

# åˆ›å»ºå®¢æˆ·ç«¯
client = GPTClient(config)

# è¯»å–æ•°æ®
df = pd.read_excel(config.data_file)

# å¤„ç†æ•°æ®
results = client.process_dataframe(df, template_type="basic")
```

#### ChatGLM

```python
from LLMs.glm_client import GLMClient
from LLMs.config import GLMConfig
import pandas as pd

# é…ç½®
config = GLMConfig(
    model_path="/path/to/chatglm2-6b/",
    data_file="data/v2/test.xlsx"
)

# åˆ›å»ºå®¢æˆ·ç«¯
client = GLMClient(config)

# å¤„ç†æ•°æ®
df = pd.read_excel(config.data_file)
results = client.process_dataframe(df, template_type="basic")
```

### 2. å¾®è°ƒBERT/RoBERTa

```bash
# è®­ç»ƒ
cd bert\&roberta
python main_train.py \
    --model_name bert \
    --num_epochs 50 \
    --train_batch_size 16 \
    --pretrained_weights ../model \
    --train_file ../data/v2/train.json \
    --save_file bert_model.params

# æµ‹è¯•
python main_test.py \
    --model_name bert \
    --save_file bert_model.params \
    --test_file ../data/v2/test.json
```

### 3. å¾®è°ƒT5

```bash
# è®­ç»ƒ
cd t5
python main_train.py \
    --pretrained_model_name_or_path ./mt5model \
    --num_train_epochs 12 \
    --batch_size 4

# æµ‹è¯•
python main_test.py \
    --weights_name mt5model-Feb16_11-59-53-epoch4.pth
```
